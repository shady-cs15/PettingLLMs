# build_testset.py
import argparse
import os
import re
from pathlib import Path
import pandas as pd
from pathlib import Path
import datasets
from verl.utils.hdfs_io import copy, makedirs
from huggingface_hub import hf_hub_download

# ---------- ç­”æ¡ˆæŠ½å–ï¼šè¦†ç›–å¸¸è§æ•°å­¦åŸºå‡†çš„æ ‡æ³¨ä¹ æƒ¯ ----------
def extract_solution(answer_text: str) -> str:
    if answer_text is None:
        return ""
    s = str(answer_text).strip()

    # GSM8K å¸¸è§å½¢å¼ï¼š#### xxx
    m = re.search(r"####\s*([^\n\r]+)", s)
    if m:
        return m.group(1).strip().replace(",", "")

    # MATH å¸¸è§ï¼š\boxed{...}
    m = re.search(r"\\boxed\{([^{}]+)\}", s)
    if m:
        return m.group(1).strip()

    # æœ«å°¾æ˜¾å¼æ ‡ç­¾ï¼šFinal answer: xxx / Answer: xxx
    m = re.search(r"(?:final answer|answer)\s*[:ï¼š]\s*([^\n\r]+)", s, re.IGNORECASE)
    if m:
        return m.group(1).strip()

    # AIME ä¹‹ç±»çŸ­ç­”æ¡ˆï¼šå–æœ€åä¸€è¡Œçš„çŸ­ token
    lines = [ln.strip() for ln in s.splitlines() if ln.strip()]
    if lines:
        tail = lines[-1]
        if re.fullmatch(r"[A-Za-z0-9\-\+\*/\.^,_]+", tail) and len(tail) <= 20:
            return tail.replace(",", "")

    return s


# ---------- å°è¯•å¤šä¸ªå€™é€‰å­—æ®µå ----------
def get_first_key(d: dict, candidates):
    for k in candidates:
        if k in d and d[k] is not None:
            return d[k]
    return ""


# ---------- äº”ä¸ªåŸºå‡†çš„æ•°æ®é›†é…ç½®ï¼ˆå…¬å¼€å¯ç”¨è·¯å¾„ï¼‰ ----------
DATASETS = {
    # AIME 2024
    # https://huggingface.co/datasets/Maxwell-Jia/AIME_2024
    "AIME24": {
        "path": "Maxwell-Jia/AIME_2024",
        "subset": None,
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["problem", "question", "prompt", "Problem"],
        "a_keys": ["answer", "final_answer", "solution", "Solution", "Answer"],
    },
    # AIME 2025
    # https://huggingface.co/datasets/yentinglin/aime_2025
    "AIME25": {
        "path": "yentinglin/aime_2025",
        "subset": None,
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["problem", "question", "prompt", "Problem"],
        "a_keys": ["answer", "final_answer", "solution", "Solution", "Answer"],
    },
    "gsm8k": {
        "path": "openai/gsm8k",
        "subset": None,
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["question", "Problem", "problem", "prompt"],
        "a_keys": ["answer", "final_answer", "solution", "Solution", "Answer"],
    },
    # MATH-500
    # https://huggingface.co/datasets/HuggingFaceH4/MATH-500
    "MATH500": {
        "path": "HuggingFaceH4/MATH-500",
        "subset": None,
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["problem", "question", "prompt"],
        "a_keys": ["solution", "answer", "final_answer"],
    },
    # Hendrycks MATH
    # https://huggingface.co/datasets/hendrycks/competition_math
    "MATH": {
        "path": "hendrycks/competition_math",
        "subset": None,
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["problem", "question", "prompt"],
        "a_keys": ["solution", "answer", "final_answer", "Solution", "Answer"],
    },
    # GSM8K
    # https://huggingface.co/datasets/openai/gsm8k
    "GSM8K": {
        "path": "openai/gsm8k",
        "subset": "main",  # å®˜æ–¹ä½¿ç”¨ main å­é›†
        "prefer_splits": ["test", "validation", "dev", "train"],
        "q_keys": ["question", "Problem", "problem", "prompt"],
        "a_keys": ["answer", "final_answer", "solution", "Solution", "Answer"],
    },
    # OlympiadBench
    # https://huggingface.co/datasets/Hothan/OlympiadBench
    "OlympiadBench": {
        "path": "Hothan/OlympiadBench",
        "subset": "OE_TO_maths_en_COMP",
        "prefer_splits": ["train", "test", "validation", "dev"],
        "q_keys": ["problem", "question", "prompt", "Problem"],
        "a_keys": ["answer", "final_answer", "solution", "Solution", "Answer"],
    },
}


def choose_available_split(ds_dict, prefer_splits):
    for sp in prefer_splits:
        if sp in ds_dict:
            return sp
    if len(ds_dict) > 0:
        return list(ds_dict.keys())[0]
    raise ValueError("No splits available in the loaded dataset.")


def download_and_process_gsm8k_test(out_dir: str):
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    project_root = Path(__file__).resolve().parents[2]
    out_dir = project_root / "datasets" / "math" / "train"
    os.makedirs(out_dir, exist_ok=True)
    
    # ä¸‹è½½gsm8kæ•°æ®é›†
    print("ğŸ“¥ ä¸‹è½½gsm8kæ•°æ®é›†...")
    ds_dict = datasets.load_dataset("openai/gsm8k", "main")
    
    # é€‰æ‹©æµ‹è¯•é›†split
    split = choose_available_split(ds_dict, ["test"])
    dataset = ds_dict[split]
    print(f"âœ… ä½¿ç”¨split: {split}ï¼ˆä½œä¸ºæµ‹è¯•é›†ï¼‰")
    
    # æå–ç­”æ¡ˆ
    def map_fn(example):
        q_raw = get_first_key(example, ["question", "Problem", "problem", "prompt"])
        a_raw = get_first_key(example, ["answer", "final_answer", "solution", "Solution", "Answer"])
        return {
            "question": q_raw,
            "solution": extract_solution(a_raw),
        }
    
    print("ğŸ”§ ç»Ÿä¸€æ˜ å°„ä¸º {solution} ...")
    dataset_std = dataset.map(map_fn, remove_columns=[c for c in dataset.column_names if c not in []])
    
    # é™åˆ¶ä¸ºå‰500æ¡
    #dataset_std = dataset_std.select(range(500))

    # å­˜å‚¨ç»“æœ
    test_path = Path(out_dir) / "gsm8k_test_full.parquet"
    dataset_std.to_parquet(str(test_path))
    print(f"ğŸ’¾ æµ‹è¯•é›†å·²ä¿å­˜åˆ°: {test_path}ï¼ˆ{len(dataset_std)} æ¡ï¼‰")



def download_and_process_olympiadbench_test(out_dir: str):
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    project_root = Path(__file__).resolve().parents[2]
    out_dir = project_root / "datasets" / "math" / "train"
    os.makedirs(out_dir, exist_ok=True)
    
    # ä¸‹è½½OlympiadBenchæ•°æ®é›†
    print("ğŸ“¥ ä¸‹è½½OlympiadBenchæ•°æ®é›†...")
    ds_dict = datasets.load_dataset("Hothan/OlympiadBench", "OE_TO_maths_en_COMP")
    
    # é€‰æ‹©è®­ç»ƒé›†split
    split = choose_available_split(ds_dict, ["train"])
    dataset = ds_dict[split]
    print(f"âœ… ä½¿ç”¨split: {split}ï¼ˆä½œä¸ºæµ‹è¯•é›†ï¼‰")
    
    # æå–ç­”æ¡ˆ
    def map_fn(example):
        q_raw = get_first_key(example, ["problem", "question", "prompt", "Problem"])
        a_raw = get_first_key(example, ["answer", "final_answer", "solution", "Solution", "Answer"])
        return {
            "question": q_raw,
            "solution": extract_solution(a_raw),
        }
    
    print("ğŸ”§ ç»Ÿä¸€æ˜ å°„ä¸º {solution} ...")
    dataset_std = dataset.map(map_fn, remove_columns=[c for c in dataset.column_names if c not in []])
    
    # å­˜å‚¨ç»“æœ
    test_path = Path(out_dir) / "OlympiadBench_test.parquet"
    dataset_std.to_parquet(str(test_path))
    print(f"ğŸ’¾ æµ‹è¯•é›†å·²ä¿å­˜åˆ°: {test_path}ï¼ˆ{len(dataset_std)} æ¡ï¼‰")
    
    # æ‰“å°ä¸€ä¸ªæ ·æœ¬
    if len(dataset_std) > 0:
        ex = dataset_std[0]
        print("\n=== æ ·æœ¬ç¤ºä¾‹ ===")
        print(f"é—®é¢˜: {ex['question']}")
        print(f"ç­”æ¡ˆ: {ex['solution']}")


def download_and_process_polaris_train(out_dir: str):
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    project_root = Path(__file__).resolve().parents[2]
    out_dir = project_root / "datasets" / "math" / "train"
    os.makedirs(out_dir, exist_ok=True)
    
    # ä¸‹è½½POLARISæ•°æ®é›†
    print("ğŸ“¥ ä¸‹è½½POLARISæ•°æ®é›†...")
    ds_dict = datasets.load_dataset("POLARIS-Project/Polaris-Dataset-53K")
    
    # é€‰æ‹©è®­ç»ƒé›†split
    split = choose_available_split(ds_dict, ["train", "test", "validation", "dev"])
    dataset = ds_dict[split]
    print(f"âœ… ä½¿ç”¨split: {split}ï¼ˆä½œä¸ºè®­ç»ƒé›†ï¼‰")
    
    # æå–ç­”æ¡ˆ - POLARISæ•°æ®é›†å­—æ®µä¸ºproblem, answer, difficulty
    def map_fn(example):
        q_raw = get_first_key(example, ["problem", "question", "prompt", "Problem"])
        a_raw = get_first_key(example, ["answer", "final_answer", "solution", "Solution", "Answer"])
        return {
            "question": q_raw,
            "solution": extract_solution(a_raw),
        }
    
    print("ğŸ”§ ç»Ÿä¸€æ˜ å°„ä¸º {question, solution} ...")
    dataset_std = dataset.map(map_fn, remove_columns=[c for c in dataset.column_names if c not in []])
    
    # å­˜å‚¨ç»“æœ
    train_path = Path(out_dir) / "train_polaris.parquet"
    dataset_std.to_parquet(str(train_path))
    print(f"ğŸ’¾ è®­ç»ƒé›†å·²ä¿å­˜åˆ°: {train_path}ï¼ˆ{len(dataset_std)} æ¡ï¼‰")
    
    # æ‰“å°ä¸€ä¸ªæ ·æœ¬
    if len(dataset_std) > 0:
        ex = dataset_std[0]
        print("\n=== æ ·æœ¬ç¤ºä¾‹ ===")
        print(f"é—®é¢˜: {ex['question']}")
        print(f"ç­”æ¡ˆ: {ex['solution']}")

def main():
    project_root = Path(__file__).resolve().parents[2]
    out_dir = project_root / "datasets" / "math" / "train"
    train_path = out_dir / "train.parquet"
    os.makedirs(out_dir, exist_ok=True)
    in_path = project_root / "openthought2_mathsubset" / "extracted_answers_capped_at_2k.parquet"
    alt = Path("openthought2_mathsubset/extracted_answers_capped_at_2k.parquet")
    df_raw = pd.read_parquet(alt)

    # åªä¿ç•™ question å’Œ answer_boxed ä¸¤åˆ—ï¼Œå¹¶é‡å‘½å
    df = df_raw[["question", "answer_boxed"]].rename(
        columns={"answer_boxed": "solution"}
    )

    # ä¿å­˜ä¸º train.parquet
    df.to_parquet(train_path, index=False)
    

    for benchmark in ["AIME24", "AIME25", "MATH500", "GSM8K", "MATH", "OlympiadBench"]:
        conf = DATASETS[benchmark]
        path = conf["path"]
        subset = conf.get("subset", None)

        # å·¥ç¨‹æ ¹ä¸é»˜è®¤è¾“å‡ºç›®å½•ï¼ˆä¸ä½ åŸå§‹è„šæœ¬ä¿æŒä¸€è‡´çš„å±‚çº§ï¼‰
        
        os.makedirs(out_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {out_dir}")

        # åŠ è½½æ•°æ®é›†
        print(f"ğŸ”„ ä» Hugging Face åŠ è½½ {path}" + (f" (subset={subset})" if subset else "") + " ...")
        ds_dict = datasets.load_dataset(path, subset) if subset else datasets.load_dataset(path)

        # é€‰æ‹©ä¸€ä¸ªå¯ç”¨ split ä½œä¸ºâ€œæµ‹è¯•é›†â€
        split = choose_available_split(ds_dict, conf["prefer_splits"])
        dataset = ds_dict[split]
        print(f"âœ… ä½¿ç”¨ split: {split}ï¼ˆä½œä¸ºæµ‹è¯•é›†ï¼‰")

        q_keys = conf["q_keys"]
        a_keys = conf["a_keys"]

        def map_fn(example):
            q_raw = get_first_key(example, q_keys)
            a_raw = get_first_key(example, a_keys)
            return {
                "question": str(q_raw).strip(),
                "solution": extract_solution(a_raw),
            }

        print("ğŸ”§ ç»Ÿä¸€æ˜ å°„ä¸º {question, solution} ...")
        dataset_std = dataset.map(map_fn, remove_columns=[c for c in dataset.column_names if c not in []])
        
        test_path = out_dir / f"{benchmark}.parquet"
        dataset_std.to_parquet(str(test_path))
        print(f"ğŸ’¾ æµ‹è¯•é›†å·²ä¿å­˜åˆ°: {test_path}ï¼ˆ{len(dataset_std)} æ¡ï¼‰")


        # æ‰“å°ä¸€ä¸ªæ ·æœ¬
        if len(dataset_std) > 0:
            ex = dataset_std[0]
            print("\n=== æ ·æœ¬ç¤ºä¾‹ ===")
            print(f"é—®é¢˜: {ex['question']}")
            print(f"ç­”æ¡ˆ: {ex['solution']}")


if __name__ == "__main__":
    out_dir = Path(__file__).resolve().parents[2] / "datasets" / "math" / "train"
    download_and_process_polaris_train(out_dir)